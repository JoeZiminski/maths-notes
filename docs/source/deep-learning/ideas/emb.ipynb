{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T17:08:31.912501Z",
     "start_time": "2025-11-29T17:08:31.361395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "eef129211259d595",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TODO: number the equations,then refer to them in code!\n",
    "DEFINE {p(\\mathbf{x})}\n",
    "TODO: go into more detail on WHAT exactly we are aiming to do (learn the distribution of x given the data!)\n",
    "\n",
    "An energy-based model (EMB) takes the form:\n",
    "\n",
    "$$\n",
    "q_\\theta(\\mathbf{x}) = \\dfrac{e^ {-E_\\theta(\\mathbf{x}) } } { \\int e^ {-E_\\theta(\\mathbf{x})} d\\mathbf{x}}\n",
    "$$\n",
    "\n",
    "where $E_\\theta(.)$ is a function returning the 'energy' of $\\mathbf{x}$ shaped to capture the likelihood of observing certain $x$. Here we will take $\\mathbf{x} \\in R^m$, so $\\mathbf{x}$ for example could be an image $n \\times n$ image as a $|n^2|$ vector. Here $\\mathbf{x}$ is a sample (i.e. single image) from the space $\\mathbf{X}$ of all possible $n \\times n$ images i.e. $\\mathbf{X}$ is a random variable $q_\\theta(\\mathbf{x})$ is a probability distribution over $\\mathbf{X}$ given a set of model parameters $\\theta$.\n",
    "\n",
    "Some brief notes on notation. First, we write $\\theta$ in the subscript by convention, but to be clear this is a set of parameters on which our model depends (e.g. we could write alternatively as $E(x;\\theta)$ or $q(x; \\theta)$). Further, the normalising constant in the denominator (also called the 'partition function') is an integral over all $\\mathbf{x}$ and so does not depend on $\\mathbf{x}$ as input to $q_\\theta(\\mathbf{x})$. It is sometimes written $Z(\\theta)$ to make this lack of dependency clear.\n",
    "\n",
    "Note that $q_\\theta(\\mathbf{x})$ takes the form of the Boltzmann distribution:\n",
    "\n",
    "$$\n",
    "p(\\epsilon_i) = \\dfrac { e^{ -\\epsilon_i  } } { \\sum_i e^{ -\\epsilon_i }}\n",
    "$$\n",
    "\n",
    "where $ \\epsilon_i = \\dfrac{ e_i } {k_B T }$ (energy $e$ of state $i$ over the Boltzmann constant $k_B$ and absolute temperature $T$, which are set to $1$ here).\n",
    "\n"
   ],
   "id": "35dcdede45c6b3d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T17:08:32.028811Z",
     "start_time": "2025-11-29T17:08:31.921700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_space = np.linspace(1, 25, 1000)\n",
    "Z = np.sum(np.exp(-sample_space))\n",
    "\n",
    "plt.plot(\n",
    "    sample_space, np.exp(-sample_space) / Z\n",
    ")\n",
    "plt.title(\"The Boltzmann Distribution\")\n",
    "plt.show()"
   ],
   "id": "caf1cfe100a0a56b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "boWe see that the Boltzmann distribution assigns high probability to low energy states.\n",
    "\n",
    "A key benefit of the EBM framework is that we can use any energy function $E_\\theta(\\mathbf{x})$ we like to model the likelihood of $\\mathbf{x}$. This means we are not restricted to models that return a normalised probability, providing a great deal of flexibility [[1]](https://atcold.github.io/NYU-DLSP20/en/week07/07-1/). As such, can take $E_\\theta(\\mathbf{x})$ to be any function $ f_\\theta : \\mathbf{X} \\to \\mathbb{R} $, typically it a neural network parameterised by $\\theta$.\n",
    "\n",
    "Once the model is trained (i.e. we have learned a distribution over $\\mathbf{X}$), we can do a number of cool things:\n",
    "- Generate new images by sampling from $q(\\mathbf{x})$\n",
    "- Recover lost parts of images by sampling from $q(\\mathbf{x})$ with MCMC using the partial images as an initialisation point\n",
    "- Check if a new, previously unobserved image is likely to have been part of the dataset (e.g. is this picture of a horse a picture of a cat?)"
   ],
   "id": "39d677a5d6d05738"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**The objective function**\n",
    "\n",
    "The Maximum likelihood approach maximises the log probability our model returns for the observed data, given a set of parameters:\n",
    "\n",
    "$$\n",
    "\\arg\\max_{\\theta} \\ \\mathbb{E}_{p(\\mathbf{x})} [ \\log q_\\theta (\\mathbf{x}) ]\n",
    "$$\n",
    "\n",
    "i.e. we want our model to match the distribution of our observed data as closely as possible. By convention, we will minimise the negative log likelihood:\n",
    "\n",
    "$$\n",
    "\\arg\\min_{\\theta} \\ -\\mathbb{E}_{p(\\mathbf{x})} [ \\log q_\\theta (\\mathbf{x}) ]\n",
    "$$\n",
    "\n",
    "Let's look at the objective function a little more closely:\n",
    "\n",
    "\\begin{aligned}\n",
    "L_{\\theta} &= -\\mathbb{E}_{p(\\mathbf{x})} \\left[ \\log q_\\theta (\\mathbf{x}) \\right] \\\\\n",
    "&= \\mathbb{E}_{p(\\mathbf{x})} \\left[E_\\theta(\\mathbf{x}) \\right] + \\log \\int e^{-E_\\theta(\\mathbf{x})} \\ dx\n",
    "\\end{aligned}\n",
    "\n",
    "Where the expectation over the second term can be  dropped because it does not depend on $\\mathbf{x}$. The form this takes is very interesting and worth thinking about. We want to optimise for parameters that lower the energy for $\\mathbf{x}$ according to the probability distribution of the real data (i.e. lower energy for more likely  $\\mathbf{x}$). However, we don't want to just globally lower the energy for all $\\mathbf{x}$. Therefore, we want to minimise the energy where $p(\\mathbf{x})$ is high, and maximise the energy elsewhere.\n"
   ],
   "id": "4dd877bffa5a5036"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "We will take the partial derivative of the loss function w.r.t $\\theta$ ($\\nabla_\\theta = \\dfrac{\\partial}{\\partial \\theta}$) for stochastic gradient descent:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta L_{\\theta} = \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta E_{\\theta} (\\mathbf{x}) \\right] - \\mathbb{E}_{q_\\theta (\\mathbf{x}) } \\left[ \\nabla_\\theta E_\\theta(\\mathbf{x}) \\right]\n",
    "$$\n",
    "\n",
    "See **Appendix A** for the derivation.\n",
    "\n",
    "$\\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta E_{\\theta} (\\mathbf{x}) \\right] = \\int p(\\mathbf{x}) \\nabla_\\theta E_{\\theta} \\ d\\mathbf{x}$ For every $\\mathbb{b} \\in X$ we will plug $\\mathbf{x}$ into our energy function $\\theta E_{\\theta} (\\mathbf{x})$ and compute the derivative at that point. We will take an average over all $\\mathbf{x}$ weighted by the 'true' probability of observing $\\mathbf{x}$ (i.e. in the real world). As we don't have access to the real world, we will estimate this distribution from our observed data.\n",
    "\n",
    "$ \\mathbb{E}_{q_\\theta (\\mathbf{x}) } \\left[ \\nabla_\\theta E_\\theta(\\mathbf{x}) \\right] = \\int q_\\theta (\\mathbf{x}) \\nabla_\\theta E_{\\theta} \\ d\\mathbf{x}$ We are doing almost exactly the same thing, but now weighted the derivatives computed from $\\mathbf{x}$ by the probability of observing $\\mathbf{x}$ according to our model.\n",
    "\n",
    "Together, this means the stationary points (zero derivative) will occur where our chosen parameters set the model distribution $q_\\theta (\\mathbf{x})$ equals to the data distribution ${p(\\mathbf{x})}$, which makes sense. As the update step is $\\theta \\leftarrow \\eta \\nabla_\\theta L$, we will move in the direction that reduces energy of the samples at our observed data (reflecting the 'true' data distribution). In contrast, we will move along the positve gradient of the energy at samples drawn from our model (i.e. non-data samples). Together this will 'push' the energy down at the observed data and 'pull' the energy up at random samples drawn from our model distribution (examplin this in more detail).\n",
    "\n",
    "We will use MCMC to sample from our model distribution and estimate the expectaion (otherwise it's tractable to sample over all possible $x$.\n"
   ],
   "id": "d4311765481b9f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Contrastive Divergence**\n",
    "\n",
    "Above, we would have to run MCMC samples (initialise randomly, wait) until convergence. This is extremely slow. Instead, we will use contrastive divergence (e.g. initiaise with data, asmple once). The benefits are much faster and something else. REF shows that when we minimise the negative log liklihood, we are equvilently minising the KL divergence between the true data distribution $p(\\mathbf{x})$ and our model distribution $q\\theta^\\infty(\\mathbf{x})$ where $\\infty$ indicates we run MCMC samples to infiinite to fully actually have the true distribution before estimating samples:\n",
    "\n",
    "$$\n",
    "\\arg\\min_{\\theta}  -\\mathbb{E}_{p(\\mathbf{x})} \\left[ \\log q_\\theta^\\infty(\\mathbf{x}) \\right] \\Leftrightarrow \\arg\\min_{\\theta}  KL( p(\\mathbf{x}) || q_\\theta^\\infty(\\mathbf{x}))\n",
    "$$\n",
    "\n",
    "See **Appendix B** for the derivation.\n",
    "\n",
    "\n",
    "In contrastive divergence, we instead only run the MCMC sampler initialised at a data point $mathbb{x_0}$ for $k$ steps, where $k$ is typically very small. This is much faster and performs well. CD thus mimisise sthe ML and an error term:\n",
    "\n",
    "$$\n",
    "CD  = KL( p(\\mathbf{x}) || q_\\theta^\\infty(\\mathbf{x})) - KL( q_\\theta^k(\\mathbf{x}) || q_\\theta^\\infty(\\mathbf{x}))\n",
    "$$\n",
    "\n",
    "Taking the derivative of this (Appendix C) we find three terms, the last of which we drop due to XXX. So we have the same as the ML but we ignoring the error term and proceeding to minimize:\n",
    "\n",
    "\n",
    "Together, the steps of our algorithm will be:\n",
    "\n",
    "TODO:\n",
    "1) finalise all bits\n",
    "2) make it more explanatory\n",
    "3) check the math :(\n",
    "4) add the code!\n",
    "5) Move onto the Gaussian version\n",
    "\n",
    "Below, we do the code which basically follows XXX very closely.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Okay, now we are ready to put everything together (algorithm)\n",
    "\n",
    "Then, very detailed code as from that tutorial."
   ],
   "id": "ddccb90e4ea4e279"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "**Appendix A**\n",
    "\n",
    "\\begin{aligned}\n",
    "\\nabla_\\theta L_{\\theta}\n",
    "&= -\\nabla_\\theta \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\log q_\\theta (\\mathbf{x}) \\right] \\\\\n",
    "&= -\\nabla_\\theta \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\log e^{-E_{\\theta} (\\mathbf{x})} - \\log \\int e^{-E_\\theta(\\mathbf{x})} \\ d\\mathbf{x} \\right] \\\\\n",
    "&= -\\nabla_\\theta \\mathbb{E}_{p(\\mathbf{x})} \\left[ -E_{\\theta} (\\mathbf{x}) \\right] - \\nabla_\\theta \\log \\int e^{-E_\\theta(\\mathbf{x})} d\\mathbf{x}\n",
    "\\end{aligned}\n",
    "\n",
    "Looking at the second term (which is constant in $\\mathbf{x}$ so we drop the expectation), we can apply the log derivative rule $\\nabla_\\theta \\log f(\\theta) = \\frac{1}{f(\\theta)} \\nabla_\\theta f(\\theta)$ then differentiation under the integral $\\nabla_\\theta \\int f(\\theta, \\mathbf{x}) \\ d\\mathbf{x} = \\int \\nabla_\\theta f(\\theta, \\mathbf{x}) \\ d\\mathbf{x}$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\nabla_\\theta \\log \\int e^{-E_\\theta(\\mathbf{x})} d\\mathbf{x}\n",
    "&= \\dfrac{1} { \\int e^{-E_\\theta(\\mathbf{x})} d\\mathbf{x}} \\nabla_\\theta  \\int e^{-E_\\theta(\\mathbf{x})} \\ d\\mathbf{x} \\\\\n",
    "&= \\dfrac{1} { \\int e^{-E_\\theta(\\mathbf{x})} d\\mathbf{x}}  \\int e^{-E_\\theta(\\mathbf{x})} \\nabla_\\theta \\left( -E_\\theta(\\mathbf{x}) \\right) \\ d\\mathbf{x} \\\\\n",
    "&=  \\int \\dfrac{e^{-E_\\theta(\\mathbf{x})}} { \\int e^{-E_\\theta(\\mathbf{x})} d\\mathbf{x}}  \\nabla_\\theta \\left( -E_\\theta(\\mathbf{x}) \\right) \\ d\\mathbf{x} \\\\\n",
    "&= \\mathbb{E}_{q_\\theta (\\mathbf{x}) } \\left[ -\\nabla_\\theta E_\\theta(\\mathbf{x}) \\right]\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "We can similarly differentiate under the integral in the first term to move the derivative into the expectation. Together this gives us the Maximum Likelihood loss for training an EBM. It is worth looking at this closely:\n",
    "\n",
    " \\begin{aligned}\n",
    "\\nabla_\\theta L_{\\theta} = \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta E_{\\theta} (\\mathbf{x}) \\right] - \\mathbb{E}_{q_\\theta (\\mathbf{x}) } \\left[ \\nabla_\\theta E_\\theta(\\mathbf{x}) \\right]\n",
    "\\end{aligned}\n"
   ],
   "id": "3e509ffe205ca08f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Appendix B**\n",
    "\n",
    "\\begin{aligned}\n",
    "KL( p(\\mathbf{x}) || q_\\theta^\\infty(\\mathbf{x})) &= \\int p(\\mathbf{x}) \\log p(\\mathbf{x}) d\\mathbf{x} - \\int p(\\mathbf{x}) \\log q_\\theta^\\infty(\\mathbf{x}) d\\mathbf{x} \\\\\n",
    "&= \\int p(\\mathbf{x}) \\log p(\\mathbf{x}) d\\mathbf{x} - \\int p(\\mathbf{x}) \\log q_\\theta^\\infty(\\mathbf{x}) d\\mathbf{x} \\\\\n",
    "&= \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\log  p(\\mathbf{x}) \\right] - \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\log  q_\\theta^\\infty(\\mathbf{x}) \\right]\n",
    "\\end{aligned}\n",
    "\n",
    "The first term does not depend on $\\theta$, and so minimising the KL divergence and ML are equivalent.  (TODO: rewrite)"
   ],
   "id": "d37879e076b06875"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Appendix C**\n",
    "\n",
    "\\begin{aligned}\n",
    "\\nabla_\\theta CD  &= \\nabla_\\theta KL( p(\\mathbf{x}) || q_\\theta^\\infty(\\mathbf{x})) - \\nabla_\\theta KL( q_\\theta^k(\\mathbf{x}) || q_\\theta^\\infty(\\mathbf{x})) \\\\\n",
    "&= \\nabla_\\theta \\int p(\\mathbf{x}) \\log  p(\\mathbf{x}) \\ d\\mathbf{x} - \\nabla_\\theta \\int p(\\mathbf{x}) \\log  q_\\theta^\\infty(\\mathbf{x}) \\ d\\mathbf{x} - \\nabla_\\theta \\int q_\\theta^k(\\mathbf{x}) \\log  q_\\theta^k(\\mathbf{x})  \\ d\\mathbf{x} + \\nabla_\\theta \\int q_\\theta^k(\\mathbf{x}) \\log  q_\\theta^\\infty(\\mathbf{x}) \\ d\\mathbf{x} \\\\\n",
    "&= 0 - \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta  \\log  q_\\theta^\\infty(\\mathbf{x}) \\right] - \\bigg( \\int  \\bigg[ \\nabla_\\theta q_\\theta^k(\\mathbf{x}) \\bigg] \\log  q_\\theta^k(\\mathbf{x}) \\ d\\mathbf{x} + \\int q_\\theta^k(\\mathbf{x}) \\bigg[\\nabla_\\theta \\log  q_\\theta^k(\\mathbf{x}) \\bigg]  \\ d\\mathbf{x} \\bigg) + \\bigg( \\int  \\bigg[ \\nabla_\\theta q_\\theta^k(\\mathbf{x}) \\bigg] \\log  q_\\theta^\\infty(\\mathbf{x}) \\ d\\mathbf{x} + \\int q_\\theta^k(\\mathbf{x}) \\bigg[\\nabla_\\theta \\log  q_\\theta^\\infty(\\mathbf{x}) \\bigg]  \\ d\\mathbf{x} \\bigg)\n",
    "\\end{aligned}"
   ],
   "id": "1c439669aa925785"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The fourth term is zero:\n",
    "\\begin{aligned}\n",
    "\\int q_\\theta^k(\\mathbf{x}) \\bigg[\\nabla_\\theta \\log  q_\\theta^k(\\mathbf{x}) \\bigg]  \\ d\\mathbf{x}\n",
    "&= \\int q_\\theta^k(\\mathbf{x}) \\dfrac{1}{q_\\theta^k(\\mathbf{x}} \\nabla_\\theta q_\\theta^k(\\mathbf{x})   \\ d\\mathbf{x} \\\\\n",
    "&= \\nabla_\\theta \\int q_\\theta^k(\\mathbf{x})   \\ d\\mathbf{x} \\\\\n",
    "&= \\nabla_\\theta 1 \\\\\n",
    "&= 0\n",
    "\\end{aligned}\n",
    "\n",
    "and we can rewrite the last term as an expectation, and we will take the MINUS DERIVATIVE EXAMPLIN so together we have:\n",
    "\\begin{aligned}\n",
    "&= \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta  \\log  q_\\theta^\\infty(\\mathbf{x}) \\right] - \\mathbb{E}_{q_\\theta^k(\\mathbf{x})} \\bigg[\\nabla_\\theta \\log  q_\\theta^\\infty(\\mathbf{x}) \\bigg]  + \\bigg( \\int  \\bigg[ \\nabla_\\theta q_\\theta^k(\\mathbf{x}) \\bigg] \\log  q_\\theta^k(\\mathbf{x}) \\ d\\mathbf{x} - \\int  \\bigg[ \\nabla_\\theta q_\\theta^k(\\mathbf{x}) \\bigg] \\log  q_\\theta^\\infty(\\mathbf{x}) \\ d\\mathbf{x} \\bigg) \\\\\n",
    "&= \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta  \\log  q_\\theta^\\infty(\\mathbf{x}) \\right] - \\mathbb{E}_{q_\\theta^k(\\mathbf{x})} \\bigg[\\nabla_\\theta \\log  q_\\theta^\\infty(\\mathbf{x}) \\bigg]  + \\int  \\bigg[ \\nabla_\\theta q_\\theta^k(\\mathbf{x}) \\bigg] \\log \\dfrac{q_\\theta^k(\\mathbf{x}}{ q_\\theta^\\infty(\\mathbf{x})} \\ d\\mathbf{x} \\\\\n",
    "&= \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\nabla_\\theta  \\log  q_\\theta^\\infty(\\mathbf{x}) \\right] - \\mathbb{E}_{q_\\theta^k(\\mathbf{x})} \\bigg[\\nabla_\\theta \\log  q_\\theta^\\infty(\\mathbf{x}) \\bigg]  + \\dfrac{\\partial q_\\theta^k(\\mathbf{x})}{\\partial  \\theta} \\dfrac{\\partial  KL( q_\\theta^k(\\mathbf{x})|| q_\\theta^{\\infty}(\\mathbf{x}))}{\\partial q_\\theta^k(\\mathbf{x})}\n",
    "\\end{aligned}\n",
    "\n",
    "The last term is from Hinton's [Product of Experts](https://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf) paper, an interesting rewriting. If you carry out the partial differentiation you can see the term matches."
   ],
   "id": "ea3412649234c027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "718a3cffa7b37f5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a5eb2dde6ca62f52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
